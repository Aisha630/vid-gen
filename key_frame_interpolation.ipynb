{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for interpolation of Keyframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "This code uses the `diffusers-0-27-0` environment\n",
    "<br>\n",
    "<span style=\"color:red\">**NOTE:** Define all imports and install/shell commands here</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# add install or other terminal commands here\n",
    "# %pip install numpy matplotlib opencv-python scikit-image scikit-video pillow\n",
    "# %pip install tabulate\n",
    "# %conda install -c conda-forge ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import subprocess\n",
    "import sys\n",
    "from KeyFrameDetector.key_frame_detector import smartKeyframeDetection\n",
    "import numpy as np\n",
    "from moviepy.editor import concatenate_videoclips, VideoFileClip\n",
    "from tabulate import tabulate\n",
    "from svd.attn_ctrl.attention_control import (\n",
    "    AttentionStore,\n",
    "    register_temporal_self_attention_control,\n",
    "    register_temporal_self_attention_flip_control,\n",
    ")\n",
    "from svd.custom_diffusers.schedulers.scheduling_euler_discrete import EulerDiscreteScheduler\n",
    "from svd.custom_diffusers.pipelines.pipeline_frame_interpolation_with_noise_injection import FrameInterpolationWithNoiseInjectionPipeline\n",
    "from diffusers import UNetSpatioTemporalConditionModel\n",
    "from diffusers.utils import load_image, export_to_video\n",
    "import time\n",
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "from utils.ffmpeg_evaluator import FFmpegEvaluator\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "os.chdir(\"/root/VideoReconstruction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "There are two functuions in this pipeline:\n",
    "\n",
    "1. `interpolate_keyframes` - This function takes in 2 keyframes and interpolates the keyframes to get the intermediate keyframes.\n",
    "2. `generate_video` - This function uses a list of keyframes and interpolates between every two consecutive keyframes to get a list of intermediate video segments which are then concatenated to get the final video.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "\n",
    "The `run_interpolation` function interpolates between two keyframes and saves the output segment video to the specifed path.\n",
    "\n",
    "The  `generate_all_interpolations` function generates all the intermediate keyframes between every two consecutive keyframes in an input directory with all the keyframes in it saving all the output videos to the output path.\n",
    "\n",
    "The `stitch_video_segments` function stitches the video segments to get the final video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_interpolation(checkpoint_dir, frame1_path, frame2_path, out_path, resize_specs, fps, pretrained_model_name_or_path, duration, num_frames, seed=42, num_inference_steps=50, weighted_average=False, noise_injection_steps=0, noise_injection_ratio=0.5, decode_chunk_size=8, device=\"cuda:0\"):\n",
    "    \"\"\"\n",
    "    Run key frame interpolation between two frames using a pretrained model and noise injection. It saves the interpolated video or gif to the specified output path.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_dir (str): Directory containing the checkpoint for the fine-tuned UNet model.\n",
    "        frame1_path (str): Path to the first frame image.\n",
    "        frame2_path (str): Path to the second frame image.\n",
    "        out_path (str): Path to save the output interpolated video or gif.\n",
    "        resize_specs (tuple): Tuple specifying the resize dimensions (width, height) for the input frames.\n",
    "        fps (int): Frames per second for the output video.\n",
    "        pretrained_model_name_or_path (str): Path or name of the pretrained model.\n",
    "        duration (int): Duration for which each frame will be displayed in the gif (in milliseconds).\n",
    "        num_frames (int): Number of frames to interpolate between the two input frames.\n",
    "        seed (int, optional): Random seed for reproducibility. Defaults to 42.\n",
    "        num_inference_steps (int, optional): Number of inference steps for the interpolation. Defaults to 50.\n",
    "        weighted_average (bool, optional): Whether to use weighted average during interpolation. Defaults to False. \n",
    "        True: Produces a video with a gradual shift from image1 to image2. This can give the effect of morphing or smooth interpolation between two images.\n",
    "        False: Maintains an equal influence of both images across all frames. This results in a more consistent combination of features from both image1 and image2.\n",
    "\n",
    "        noise_injection_steps (int, optional): Number of steps for noise injection. Defaults to 0.\n",
    "        noise_injection_ratio (float, optional): Ratio of noise injection. Defaults to 0.5.\n",
    "        decode_chunk_size (int, optional): Chunk size for decoding. Defaults to 8. controls how many frames are decoded at a time from the latent representations during the video generation process.\n",
    "\n",
    "\n",
    "        device (str, optional): Device to run the interpolation on. Defaults to \"cuda:0\".\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load noise scheduler and pipeline\n",
    "    noise_scheduler = EulerDiscreteScheduler.from_pretrained(\n",
    "        pretrained_model_name_or_path, subfolder=\"scheduler\")\n",
    "\n",
    "    pipe = FrameInterpolationWithNoiseInjectionPipeline.from_pretrained(\n",
    "        pretrained_model_name_or_path, scheduler=noise_scheduler, variant=\"fp16\", torch_dtype=torch.float16)\n",
    "\n",
    "    # Set up UNet model for fine-tuning and load state dicts\n",
    "\n",
    "    ref_unet = pipe.ori_unet\n",
    "    state_dict = pipe.unet.state_dict()\n",
    "\n",
    "    # Compute delta weights\n",
    "    finetuned_unet = UNetSpatioTemporalConditionModel.from_pretrained(\n",
    "        checkpoint_dir, subfolder=\"unet\", torch_dtype=torch.float16)\n",
    "\n",
    "    ori_unet = UNetSpatioTemporalConditionModel.from_pretrained(\n",
    "        pretrained_model_name_or_path, subfolder=\"unet\", variant=\"fp16\", torch_dtype=torch.float16)\n",
    "\n",
    "    # Apply delta to state dict for specific layers\n",
    "    finetuned_state_dict = finetuned_unet.state_dict()\n",
    "    ori_state_dict = ori_unet.state_dict()\n",
    "    for name, param in finetuned_state_dict.items():\n",
    "        if \"temporal_transformer_blocks.0.attn1.to_v\" in name or \"temporal_transformer_blocks.0.attn1.to_out.0\" in name:\n",
    "            delta_w = param - ori_state_dict[name]\n",
    "            state_dict[name] = state_dict[name] + delta_w\n",
    "    pipe.unet.load_state_dict(state_dict)\n",
    "\n",
    "    # Setup attention controllers\n",
    "    controller_ref = AttentionStore()\n",
    "    register_temporal_self_attention_control(ref_unet, controller_ref)\n",
    "\n",
    "    controller = AttentionStore()\n",
    "    register_temporal_self_attention_flip_control(\n",
    "        pipe.unet, controller, controller_ref)\n",
    "\n",
    "    # Move pipeline to specified device\n",
    "    pipe = pipe.to(device)\n",
    "\n",
    "    # Set random seed\n",
    "    generator = torch.Generator(device=device)\n",
    "    if seed is not None:\n",
    "        generator = generator.manual_seed(seed)\n",
    "\n",
    "    # Load and resize frames\n",
    "    frame1 = load_image(frame1_path).resize(resize_specs)\n",
    "    frame2 = load_image(frame2_path).resize(resize_specs)\n",
    "\n",
    "    timestamp_f1 = frame1_path.split(\"_\")[1]\n",
    "    timestamp_f2 = frame2_path.split(\"_\")[1]\n",
    "    timestamp_f1 = timestamp_f1.split(\".jpg\")[0]\n",
    "    timestamp_f2 = timestamp_f2.split(\".jpg\")[0]\n",
    "  \n",
    "\n",
    "    num_frames = int(\n",
    "        np.round((float(timestamp_f2) - float(timestamp_f1)) * fps))\n",
    "    \n",
    "    # fps = np.round(num_frames / np.round(float(timestamp_f2) - float(timestamp_f1)))\n",
    "    \n",
    "    print(\"Interpolating between frames at timestamps\", frame1_path, frame2_path)\n",
    "    \n",
    "    print(\"The num frames is \", num_frames)\n",
    "    print(\"The fps is \", fps)\n",
    "\n",
    "    frames = pipe(image1=frame1, image2=frame2, num_inference_steps=num_inference_steps, generator=generator, weighted_average=False,\n",
    "                  noise_injection_steps=noise_injection_steps, noise_injection_ratio=noise_injection_ratio, num_frames=num_frames, decode_chunk_size=decode_chunk_size, fps=fps).frames[0]\n",
    "    # frames = pipe(image1=frame1, image2=frame2, num_inference_steps=num_inference_steps, generator=generator, weighted_average=True,\n",
    "    #               noise_injection_steps=noise_injection_steps, noise_injection_ratio=noise_injection_ratio, num_frames=num_frames, decode_chunk_size=7, motion_bucket_id=200).frames[0]\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    # duration = the time  for whicch each frame will be displayed in the gif\n",
    "    if out_path.endswith(\".gif\"):\n",
    "        print(f\"Saving {len(frames)} frames to {out_path} as gif\")\n",
    "        frames[0].save(out_path, save_all=True,\n",
    "                       append_images=frames[1:], duration=duration, loop=0)\n",
    "    else:\n",
    "        print(f\"Saving {len(frames)} frames to {out_path} as video\")\n",
    "        export_to_video(frames, out_path, fps=fps)\n",
    "\n",
    "    print(f\"Interpolated video saved to {out_path}\")\n",
    "\n",
    "    # Free GPU memory after inference\n",
    "    del controller, controller_ref, ori_unet, finetuned_unet\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_interpolations(checkpoint_dir, input_sub_dir, output_dir, model_name, num_frames, decode_chunk_size, extension=\".gif\", resize_specs=(1024, 576), fps=7, duration=142, seed=42, inference_steps=20, noise_injection_steps=2, noise_injection_ratio=0.5, device=\"cuda:0\", video_name=None):\n",
    "    \"\"\"\n",
    "    Generates interpolated videos from key frames in the input directory.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_dir (str): Directory containing the model checkpoints.\n",
    "        input_sub_dir (str): Directory containing the input frames.\n",
    "        output_dir (str): Directory to save the output videos.\n",
    "        model_name (str): Name of the pre-trained model to use for interpolation.\n",
    "        num_frames (int): Number of frames to generate between each pair of key frames.\n",
    "        decode_chunk_size (int): Size of the chunk to decode.\n",
    "        extension (str, optional): Extension of the output video files. Defaults to \".gif\".\n",
    "        resize_specs (tuple, optional): Tuple specifying the width and height to resize the frames. Defaults to (1024, 576).\n",
    "        fps (int, optional): Frames per second for the output video. Defaults to 7.\n",
    "        duration (int, optional): Duration of the output video in seconds. Defaults to 142.\n",
    "        seed (int, optional): Random seed for reproducibility. Defaults to 42.\n",
    "        inference_steps (int, optional): Number of inference steps for the model. Defaults to 20.\n",
    "        noise_injection_steps (int, optional): Number of steps to inject noise during inference. Defaults to 2.\n",
    "        noise_injection_ratio (float, optional): Ratio of noise to inject during inference. Defaults to 0.5.\n",
    "        device (str, optional): Device to run the model on. Defaults to \"cuda:0\".\n",
    "        video_name (str, optional): Name of the video. If None, it will be derived from the input_sub_dir. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    video_name = os.path.basename(input_sub_dir)\n",
    "\n",
    "    intermediate_videos_dir = os.path.join(\n",
    "        output_dir, f\"interm_videos_{video_name}\")\n",
    "    os.makedirs(intermediate_videos_dir, exist_ok=True)\n",
    "\n",
    "    frames = sorted([os.path.join(input_sub_dir, f) for f in os.listdir(\n",
    "        input_sub_dir) if f.endswith((\".png\", \".jpeg\", \".jpg\"))])\n",
    "\n",
    "    print(f\"Found {len(frames)} frames in {input_sub_dir}\")\n",
    "    \n",
    "    if len(frames) < 2:\n",
    "        print(f\"Skipping {video_name} as it has less than 2 frames\")\n",
    "        return\n",
    "\n",
    "    frames = sorted(frames, key=lambda x: float(\n",
    "        x.split(\"_\")[-1].replace(\".jpg\", \"\")))\n",
    "    \n",
    "    for i in range(len(frames) - 1):\n",
    "        frame1_path = frames[i]\n",
    "        frame2_path = frames[i + 1]\n",
    "\n",
    "        print(f\"Interpolating between frames {frame1_path} and {frame2_path}\")\n",
    "\n",
    "        if \"<s>\" in frame1_path:\n",
    "            print(f\"Skipping {frame1_path} as its entrie bucket is already saved\")\n",
    "            continue\n",
    "        \n",
    "        segment_output_path = os.path.join(\n",
    "            intermediate_videos_dir, f\"segment_{i}{extension}\")\n",
    "\n",
    "        run_interpolation(\n",
    "            checkpoint_dir=checkpoint_dir,\n",
    "            frame1_path=frame1_path,\n",
    "            frame2_path=frame2_path,\n",
    "            out_path=segment_output_path,\n",
    "            resize_specs=resize_specs,\n",
    "            fps=fps,\n",
    "            pretrained_model_name_or_path=model_name,\n",
    "            duration=duration,\n",
    "            seed=seed,\n",
    "            num_inference_steps=inference_steps,\n",
    "            noise_injection_ratio=noise_injection_ratio,\n",
    "            noise_injection_steps=noise_injection_steps,\n",
    "            num_frames=num_frames,\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_video_segments(intermediate_videos_dir, output_path, fps):\n",
    "    \"\"\"\n",
    "    Stitches together video segments from a specified directory into a single video file.\n",
    "\n",
    "    Args:\n",
    "        intermediate_videos_dir (str): The directory containing the video segments to be stitched together.\n",
    "        output_path (str): The file path where the final stitched video will be saved.\n",
    "        fps (int): The frames per second (fps) rate for the final video.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Prints:\n",
    "        The number of segments found and a confirmation message when the final video is saved.\n",
    "    \"\"\"\n",
    "    segment_paths = sorted([os.path.join(intermediate_videos_dir, f)\n",
    "                           for f in os.listdir(intermediate_videos_dir)])\n",
    "\n",
    "    print(f\"Found {len(segment_paths)} segments to stitch.\")\n",
    "    clips = [VideoFileClip(segment).set_fps(fps) for segment in segment_paths]\n",
    "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
    "    final_video.write_videofile(output_path, fps=fps)\n",
    "    print(f\"Final video saved to {output_path}\")\n",
    "\n",
    "    for clip in clips:\n",
    "        clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_videos(input_dir, trim_length, output_dir):\n",
    "    \"\"\"\n",
    "    Trims all videos in the specified directory to the specified length.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): The directory containing the videos to be trimmed.\n",
    "        trim_length (int): The duration to trim the videos to (in seconds).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Prints:\n",
    "        A confirmation message when the trimmed videos are saved.\n",
    "    \"\"\"\n",
    "    video_paths = [os.path.join(input_dir, f)\n",
    "                   for f in os.listdir(input_dir) if f.endswith((\".mp4\"))]\n",
    "    already_trimmed = [os.path.basename(i) for i in os.listdir(output_dir)]\n",
    "    \n",
    "\n",
    "    for video_path in video_paths:\n",
    "        video_name = os.path.basename(video_path)\n",
    "        \n",
    "        if video_name in already_trimmed:\n",
    "            print(f\"Skipping {video_name} as it is already trimmed\")\n",
    "            continue\n",
    "        \n",
    "        video = VideoFileClip(video_path)\n",
    "        trimmed_video = video.subclip(0, trim_length)\n",
    "        trimmed_video.write_videofile(os.path.join(output_dir, video_name), codec=\"libx264\", fps=video.fps, audio_codec=\"aac\"), \n",
    "        trimmed_video.close()\n",
    "        video.close()\n",
    "\n",
    "    print(f\"Trimmed videos saved to {input_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untrimmed_dir = \"/root/VideoReconstruction/original_vids/\"\n",
    "# output_dir_trimmed = \"/root/VideoReconstruction/input_videos/\"\n",
    "# trim_videos(untrimmed_dir, 10, output_dir_trimmed )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyframe Generation and Savings Analysis\n",
    "\n",
    "This part of the code processes all the videos in the input folder, generating keyframes for each video and storing them in the output folder. It also benchmarks the file sizes of the original videos and the videos reconstructed from the keyframes.\n",
    "\n",
    "To ensure a fair comparison, the original videos—initially in 4K resolution—are resized to match the resolution of the videos that can be generated by our system, which is currently limited to 1024x576 due to hardware and model constraints. By resizing the original videos to 1024x576 before conducting the bandwidth savings analysis, we maintain consistency and avoid skewing results caused by differences in resolution.\n",
    "\n",
    "To further standardize the comparison, the same codec (`libx264`) and bitrate are applied to both the resized original videos and the videos reconstructed from keyframes. This ensures that differences in compression settings do not affect the analysis, making the results reflect genuine bandwidth savings attributable to keyframe interpolation.\n",
    "\n",
    "> **Note:** While the output videos are limited to 1024x576 resolution, the keyframes are still generated from the original 4K frames. This approach leverages the higher quality of 4K frames during interpolation, resulting in better-quality reconstructed videos even though the final resolution is reduced to 1024x576. This ensures that the interpolation process operates on the highest possible quality inputs, maximizing the fidelity of the generated videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directory_size(directory):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            total_size += os.path.getsize(filepath)\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_size_in_frames = 60  # Number of frames in each bucket/segment of the video. We will chunk the video into these many frames per chunk and then interpolate between the keyframes in each bucket.\n",
    "threshold = 0.3  # Threshold for the keyframe detection algorithm. The higher the threshold, the fewer the keyframes.\n",
    "minimum_frames_in_between = 20  # Minimum number of frames between two keyframes.\n",
    "maximum_frames_in_between = 25  # Maximum number of frames between two keyframes.\n",
    "top_k_no_interpolation = 0  # Number of buckets for which we will not do any interpolation. We will just copy the frames as it is. This is to ensure that high motion segments are not interpolated and the motion is preserved.\n",
    "segment_fps = 15  # FPS of the video segments that we will NOT interpolate as defined by top_k_no_interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping multiplewaterfalls as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/multiplewaterfalls.mp4, selected 2 frames, and inserted 10 frames.\n",
      "Skipping pancakechocolate as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/pancakechocolate.mp4, selected 2 frames, and inserted 9 frames.\n",
      "Skipping inkmixing as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/inkmixing.mp4, selected 2 frames, and inserted 9 frames.\n",
      "Skipping girleatingcakespoon as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/girleatingcakespoon.mp4, selected 2 frames, and inserted 10 frames.\n",
      "Skipping coffeeart as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/coffeeart.mp4, selected 2 frames, and inserted 8 frames.\n",
      "Skipping tallwaterfall as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/tallwaterfall.mp4, selected 2 frames, and inserted 10 frames.\n",
      "Skipping countrysideaerial as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/countrysideaerial.mp4, selected 2 frames, and inserted 10 frames.\n",
      "Skipping yellowinkflowing as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/yellowinkflowing.mp4, selected 2 frames, and inserted 8 frames.\n",
      "Skipping stormcloundsaerial as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/stormcloundsaerial.mp4, selected 2 frames, and inserted 9 frames.\n",
      "Skipping riverthroughboulders as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/riverthroughboulders.mp4, selected 2 frames, and inserted 10 frames.\n",
      "Skipping waterfallthroughrockymountain as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/waterfallthroughrockymountain.mp4, selected 2 frames, and inserted 11 frames.\n",
      "Skipping nightsky as it is already processed\n",
      "For /root/VideoReconstruction/alloriginalvids/nightsky.mp4, selected 2 frames, and inserted 9 frames.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_93a06 th {\n",
       "  font-weight: bold;\n",
       "  background-color: #000000;\n",
       "}\n",
       "#T_93a06_row0_col0, #T_93a06_row0_col1, #T_93a06_row0_col2, #T_93a06_row0_col3, #T_93a06_row0_col4, #T_93a06_row0_col5, #T_93a06_row0_col6, #T_93a06_row0_col7, #T_93a06_row0_col8, #T_93a06_row1_col0, #T_93a06_row1_col1, #T_93a06_row1_col2, #T_93a06_row1_col3, #T_93a06_row1_col4, #T_93a06_row1_col5, #T_93a06_row1_col6, #T_93a06_row1_col7, #T_93a06_row1_col8, #T_93a06_row2_col0, #T_93a06_row2_col1, #T_93a06_row2_col2, #T_93a06_row2_col3, #T_93a06_row2_col4, #T_93a06_row2_col5, #T_93a06_row2_col6, #T_93a06_row2_col7, #T_93a06_row2_col8, #T_93a06_row3_col0, #T_93a06_row3_col1, #T_93a06_row3_col2, #T_93a06_row3_col3, #T_93a06_row3_col4, #T_93a06_row3_col5, #T_93a06_row3_col6, #T_93a06_row3_col7, #T_93a06_row3_col8, #T_93a06_row4_col0, #T_93a06_row4_col1, #T_93a06_row4_col2, #T_93a06_row4_col3, #T_93a06_row4_col4, #T_93a06_row4_col5, #T_93a06_row4_col6, #T_93a06_row4_col7, #T_93a06_row4_col8, #T_93a06_row5_col0, #T_93a06_row5_col1, #T_93a06_row5_col2, #T_93a06_row5_col3, #T_93a06_row5_col4, #T_93a06_row5_col5, #T_93a06_row5_col6, #T_93a06_row5_col7, #T_93a06_row5_col8, #T_93a06_row6_col0, #T_93a06_row6_col1, #T_93a06_row6_col2, #T_93a06_row6_col3, #T_93a06_row6_col4, #T_93a06_row6_col5, #T_93a06_row6_col6, #T_93a06_row6_col7, #T_93a06_row6_col8, #T_93a06_row7_col0, #T_93a06_row7_col1, #T_93a06_row7_col2, #T_93a06_row7_col3, #T_93a06_row7_col4, #T_93a06_row7_col5, #T_93a06_row7_col6, #T_93a06_row7_col7, #T_93a06_row7_col8, #T_93a06_row8_col0, #T_93a06_row8_col1, #T_93a06_row8_col2, #T_93a06_row8_col3, #T_93a06_row8_col4, #T_93a06_row8_col5, #T_93a06_row8_col6, #T_93a06_row8_col7, #T_93a06_row8_col8, #T_93a06_row9_col0, #T_93a06_row9_col1, #T_93a06_row9_col2, #T_93a06_row9_col3, #T_93a06_row9_col4, #T_93a06_row9_col5, #T_93a06_row9_col6, #T_93a06_row9_col7, #T_93a06_row9_col8, #T_93a06_row10_col0, #T_93a06_row10_col1, #T_93a06_row10_col2, #T_93a06_row10_col3, #T_93a06_row10_col4, #T_93a06_row10_col5, #T_93a06_row10_col6, #T_93a06_row10_col7, #T_93a06_row10_col8, #T_93a06_row11_col0, #T_93a06_row11_col1, #T_93a06_row11_col2, #T_93a06_row11_col3, #T_93a06_row11_col4, #T_93a06_row11_col5, #T_93a06_row11_col6, #T_93a06_row11_col7, #T_93a06_row11_col8, #T_93a06_row12_col0, #T_93a06_row12_col1, #T_93a06_row12_col2, #T_93a06_row12_col3, #T_93a06_row12_col4, #T_93a06_row12_col5, #T_93a06_row12_col6, #T_93a06_row12_col7, #T_93a06_row12_col8, #T_93a06_row13_col0, #T_93a06_row13_col1, #T_93a06_row13_col2, #T_93a06_row13_col3, #T_93a06_row13_col4, #T_93a06_row13_col5, #T_93a06_row13_col6, #T_93a06_row13_col7, #T_93a06_row13_col8, #T_93a06_row14_col0, #T_93a06_row14_col1, #T_93a06_row14_col2, #T_93a06_row14_col3, #T_93a06_row14_col4, #T_93a06_row14_col5, #T_93a06_row14_col6, #T_93a06_row14_col7, #T_93a06_row14_col8, #T_93a06_row15_col0, #T_93a06_row15_col1, #T_93a06_row15_col2, #T_93a06_row15_col3, #T_93a06_row15_col4, #T_93a06_row15_col5, #T_93a06_row15_col6, #T_93a06_row15_col7, #T_93a06_row15_col8, #T_93a06_row16_col0, #T_93a06_row16_col1, #T_93a06_row16_col2, #T_93a06_row16_col3, #T_93a06_row16_col4, #T_93a06_row16_col5, #T_93a06_row16_col6, #T_93a06_row16_col7, #T_93a06_row16_col8, #T_93a06_row17_col0, #T_93a06_row17_col1, #T_93a06_row17_col2, #T_93a06_row17_col3, #T_93a06_row17_col4, #T_93a06_row17_col5, #T_93a06_row17_col6, #T_93a06_row17_col7, #T_93a06_row17_col8, #T_93a06_row18_col0, #T_93a06_row18_col1, #T_93a06_row18_col2, #T_93a06_row18_col3, #T_93a06_row18_col4, #T_93a06_row18_col5, #T_93a06_row18_col6, #T_93a06_row18_col7, #T_93a06_row18_col8, #T_93a06_row19_col0, #T_93a06_row19_col1, #T_93a06_row19_col2, #T_93a06_row19_col3, #T_93a06_row19_col4, #T_93a06_row19_col5, #T_93a06_row19_col6, #T_93a06_row19_col7, #T_93a06_row19_col8, #T_93a06_row20_col0, #T_93a06_row20_col1, #T_93a06_row20_col2, #T_93a06_row20_col3, #T_93a06_row20_col4, #T_93a06_row20_col5, #T_93a06_row20_col6, #T_93a06_row20_col7, #T_93a06_row20_col8, #T_93a06_row21_col0, #T_93a06_row21_col1, #T_93a06_row21_col2, #T_93a06_row21_col3, #T_93a06_row21_col4, #T_93a06_row21_col5, #T_93a06_row21_col6, #T_93a06_row21_col7, #T_93a06_row21_col8, #T_93a06_row22_col0, #T_93a06_row22_col1, #T_93a06_row22_col2, #T_93a06_row22_col3, #T_93a06_row22_col4, #T_93a06_row22_col5, #T_93a06_row22_col6, #T_93a06_row22_col7, #T_93a06_row22_col8, #T_93a06_row23_col0, #T_93a06_row23_col1, #T_93a06_row23_col2, #T_93a06_row23_col3, #T_93a06_row23_col4, #T_93a06_row23_col5, #T_93a06_row23_col6, #T_93a06_row23_col7, #T_93a06_row23_col8, #T_93a06_row24_col0, #T_93a06_row24_col1, #T_93a06_row24_col2, #T_93a06_row24_col3, #T_93a06_row24_col4, #T_93a06_row24_col5, #T_93a06_row24_col6, #T_93a06_row24_col7, #T_93a06_row24_col8, #T_93a06_row25_col0, #T_93a06_row25_col1, #T_93a06_row25_col2, #T_93a06_row25_col3, #T_93a06_row25_col4, #T_93a06_row25_col5, #T_93a06_row25_col6, #T_93a06_row25_col7, #T_93a06_row25_col8, #T_93a06_row26_col0, #T_93a06_row26_col1, #T_93a06_row26_col2, #T_93a06_row26_col3, #T_93a06_row26_col4, #T_93a06_row26_col5, #T_93a06_row26_col6, #T_93a06_row26_col7, #T_93a06_row26_col8, #T_93a06_row27_col0, #T_93a06_row27_col1, #T_93a06_row27_col2, #T_93a06_row27_col3, #T_93a06_row27_col4, #T_93a06_row27_col5, #T_93a06_row27_col6, #T_93a06_row27_col7, #T_93a06_row27_col8 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_93a06\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_93a06_level0_col0\" class=\"col_heading level0 col0\" >Video Name</th>\n",
       "      <th id=\"T_93a06_level0_col1\" class=\"col_heading level0 col1\" >Original Size</th>\n",
       "      <th id=\"T_93a06_level0_col2\" class=\"col_heading level0 col2\" >Total Frames</th>\n",
       "      <th id=\"T_93a06_level0_col3\" class=\"col_heading level0 col3\" >FPS</th>\n",
       "      <th id=\"T_93a06_level0_col4\" class=\"col_heading level0 col4\" >Total Keyframes</th>\n",
       "      <th id=\"T_93a06_level0_col5\" class=\"col_heading level0 col5\" >Keyframes Size</th>\n",
       "      <th id=\"T_93a06_level0_col6\" class=\"col_heading level0 col6\" >Compressed Video Size</th>\n",
       "      <th id=\"T_93a06_level0_col7\" class=\"col_heading level0 col7\" >Savings Original Video</th>\n",
       "      <th id=\"T_93a06_level0_col8\" class=\"col_heading level0 col8\" >Savings Keyframes Video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_93a06_row0_col0\" class=\"data row0 col0\" >forest.mp4</td>\n",
       "      <td id=\"T_93a06_row0_col1\" class=\"data row0 col1\" >3.79 MB</td>\n",
       "      <td id=\"T_93a06_row0_col2\" class=\"data row0 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row0_col3\" class=\"data row0 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row0_col4\" class=\"data row0 col4\" >13</td>\n",
       "      <td id=\"T_93a06_row0_col5\" class=\"data row0 col5\" >36.82 MB</td>\n",
       "      <td id=\"T_93a06_row0_col6\" class=\"data row0 col6\" >0.08 MB</td>\n",
       "      <td id=\"T_93a06_row0_col7\" class=\"data row0 col7\" >97.83 %</td>\n",
       "      <td id=\"T_93a06_row0_col8\" class=\"data row0 col8\" >968.72 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_93a06_row1_col0\" class=\"data row1 col0\" >fog.mp4</td>\n",
       "      <td id=\"T_93a06_row1_col1\" class=\"data row1 col1\" >0.78 MB</td>\n",
       "      <td id=\"T_93a06_row1_col2\" class=\"data row1 col2\" >179</td>\n",
       "      <td id=\"T_93a06_row1_col3\" class=\"data row1 col3\" >24.00 FPS</td>\n",
       "      <td id=\"T_93a06_row1_col4\" class=\"data row1 col4\" >8</td>\n",
       "      <td id=\"T_93a06_row1_col5\" class=\"data row1 col5\" >9.64 MB</td>\n",
       "      <td id=\"T_93a06_row1_col6\" class=\"data row1 col6\" >0.03 MB</td>\n",
       "      <td id=\"T_93a06_row1_col7\" class=\"data row1 col7\" >95.65 %</td>\n",
       "      <td id=\"T_93a06_row1_col8\" class=\"data row1 col8\" >1229.76 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_93a06_row2_col0\" class=\"data row2 col0\" >multiplewaterfalls.mp4</td>\n",
       "      <td id=\"T_93a06_row2_col1\" class=\"data row2 col1\" >7.23 MB</td>\n",
       "      <td id=\"T_93a06_row2_col2\" class=\"data row2 col2\" >299</td>\n",
       "      <td id=\"T_93a06_row2_col3\" class=\"data row2 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row2_col4\" class=\"data row2 col4\" >12</td>\n",
       "      <td id=\"T_93a06_row2_col5\" class=\"data row2 col5\" >44.55 MB</td>\n",
       "      <td id=\"T_93a06_row2_col6\" class=\"data row2 col6\" >0.11 MB</td>\n",
       "      <td id=\"T_93a06_row2_col7\" class=\"data row2 col7\" >98.43 %</td>\n",
       "      <td id=\"T_93a06_row2_col8\" class=\"data row2 col8\" >614.22 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_93a06_row3_col0\" class=\"data row3 col0\" >pancakechocolate.mp4</td>\n",
       "      <td id=\"T_93a06_row3_col1\" class=\"data row3 col1\" >0.59 MB</td>\n",
       "      <td id=\"T_93a06_row3_col2\" class=\"data row3 col2\" >250</td>\n",
       "      <td id=\"T_93a06_row3_col3\" class=\"data row3 col3\" >25.00 FPS</td>\n",
       "      <td id=\"T_93a06_row3_col4\" class=\"data row3 col4\" >11</td>\n",
       "      <td id=\"T_93a06_row3_col5\" class=\"data row3 col5\" >7.34 MB</td>\n",
       "      <td id=\"T_93a06_row3_col6\" class=\"data row3 col6\" >0.03 MB</td>\n",
       "      <td id=\"T_93a06_row3_col7\" class=\"data row3 col7\" >95.36 %</td>\n",
       "      <td id=\"T_93a06_row3_col8\" class=\"data row3 col8\" >1230.35 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_93a06_row4_col0\" class=\"data row4 col0\" >motorway.mp4</td>\n",
       "      <td id=\"T_93a06_row4_col1\" class=\"data row4 col1\" >1.61 MB</td>\n",
       "      <td id=\"T_93a06_row4_col2\" class=\"data row4 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row4_col3\" class=\"data row4 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row4_col4\" class=\"data row4 col4\" >12</td>\n",
       "      <td id=\"T_93a06_row4_col5\" class=\"data row4 col5\" >23.00 MB</td>\n",
       "      <td id=\"T_93a06_row4_col6\" class=\"data row4 col6\" >0.05 MB</td>\n",
       "      <td id=\"T_93a06_row4_col7\" class=\"data row4 col7\" >96.77 %</td>\n",
       "      <td id=\"T_93a06_row4_col8\" class=\"data row4 col8\" >1422.16 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_93a06_row5_col0\" class=\"data row5 col0\" >cliffs.mp4</td>\n",
       "      <td id=\"T_93a06_row5_col1\" class=\"data row5 col1\" >2.58 MB</td>\n",
       "      <td id=\"T_93a06_row5_col2\" class=\"data row5 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row5_col3\" class=\"data row5 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row5_col4\" class=\"data row5 col4\" >13</td>\n",
       "      <td id=\"T_93a06_row5_col5\" class=\"data row5 col5\" >27.10 MB</td>\n",
       "      <td id=\"T_93a06_row5_col6\" class=\"data row5 col6\" >0.05 MB</td>\n",
       "      <td id=\"T_93a06_row5_col7\" class=\"data row5 col7\" >97.92 %</td>\n",
       "      <td id=\"T_93a06_row5_col8\" class=\"data row5 col8\" >1048.71 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_93a06_row6_col0\" class=\"data row6 col0\" >inkmixing.mp4</td>\n",
       "      <td id=\"T_93a06_row6_col1\" class=\"data row6 col1\" >1.14 MB</td>\n",
       "      <td id=\"T_93a06_row6_col2\" class=\"data row6 col2\" >250</td>\n",
       "      <td id=\"T_93a06_row6_col3\" class=\"data row6 col3\" >25.00 FPS</td>\n",
       "      <td id=\"T_93a06_row6_col4\" class=\"data row6 col4\" >11</td>\n",
       "      <td id=\"T_93a06_row6_col5\" class=\"data row6 col5\" >9.93 MB</td>\n",
       "      <td id=\"T_93a06_row6_col6\" class=\"data row6 col6\" >0.03 MB</td>\n",
       "      <td id=\"T_93a06_row6_col7\" class=\"data row6 col7\" >97.48 %</td>\n",
       "      <td id=\"T_93a06_row6_col8\" class=\"data row6 col8\" >867.77 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_93a06_row7_col0\" class=\"data row7 col0\" >coast.mp4</td>\n",
       "      <td id=\"T_93a06_row7_col1\" class=\"data row7 col1\" >1.55 MB</td>\n",
       "      <td id=\"T_93a06_row7_col2\" class=\"data row7 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row7_col3\" class=\"data row7 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row7_col4\" class=\"data row7 col4\" >12</td>\n",
       "      <td id=\"T_93a06_row7_col5\" class=\"data row7 col5\" >22.41 MB</td>\n",
       "      <td id=\"T_93a06_row7_col6\" class=\"data row7 col6\" >0.03 MB</td>\n",
       "      <td id=\"T_93a06_row7_col7\" class=\"data row7 col7\" >97.83 %</td>\n",
       "      <td id=\"T_93a06_row7_col8\" class=\"data row7 col8\" >1443.79 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_93a06_row8_col0\" class=\"data row8 col0\" >fisher.mp4</td>\n",
       "      <td id=\"T_93a06_row8_col1\" class=\"data row8 col1\" >0.91 MB</td>\n",
       "      <td id=\"T_93a06_row8_col2\" class=\"data row8 col2\" >250</td>\n",
       "      <td id=\"T_93a06_row8_col3\" class=\"data row8 col3\" >25.00 FPS</td>\n",
       "      <td id=\"T_93a06_row8_col4\" class=\"data row8 col4\" >9</td>\n",
       "      <td id=\"T_93a06_row8_col5\" class=\"data row8 col5\" >4.15 MB</td>\n",
       "      <td id=\"T_93a06_row8_col6\" class=\"data row8 col6\" >0.02 MB</td>\n",
       "      <td id=\"T_93a06_row8_col7\" class=\"data row8 col7\" >97.27 %</td>\n",
       "      <td id=\"T_93a06_row8_col8\" class=\"data row8 col8\" >454.45 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_93a06_row9_col0\" class=\"data row9 col0\" >girleatingcakespoon.mp4</td>\n",
       "      <td id=\"T_93a06_row9_col1\" class=\"data row9 col1\" >0.87 MB</td>\n",
       "      <td id=\"T_93a06_row9_col2\" class=\"data row9 col2\" >250</td>\n",
       "      <td id=\"T_93a06_row9_col3\" class=\"data row9 col3\" >25.00 FPS</td>\n",
       "      <td id=\"T_93a06_row9_col4\" class=\"data row9 col4\" >12</td>\n",
       "      <td id=\"T_93a06_row9_col5\" class=\"data row9 col5\" >12.38 MB</td>\n",
       "      <td id=\"T_93a06_row9_col6\" class=\"data row9 col6\" >0.03 MB</td>\n",
       "      <td id=\"T_93a06_row9_col7\" class=\"data row9 col7\" >96.02 %</td>\n",
       "      <td id=\"T_93a06_row9_col8\" class=\"data row9 col8\" >1413.08 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_93a06_row10_col0\" class=\"data row10 col0\" >coffeeart.mp4</td>\n",
       "      <td id=\"T_93a06_row10_col1\" class=\"data row10 col1\" >0.82 MB</td>\n",
       "      <td id=\"T_93a06_row10_col2\" class=\"data row10 col2\" >240</td>\n",
       "      <td id=\"T_93a06_row10_col3\" class=\"data row10 col3\" >24.00 FPS</td>\n",
       "      <td id=\"T_93a06_row10_col4\" class=\"data row10 col4\" >10</td>\n",
       "      <td id=\"T_93a06_row10_col5\" class=\"data row10 col5\" >4.81 MB</td>\n",
       "      <td id=\"T_93a06_row10_col6\" class=\"data row10 col6\" >0.02 MB</td>\n",
       "      <td id=\"T_93a06_row10_col7\" class=\"data row10 col7\" >97.46 %</td>\n",
       "      <td id=\"T_93a06_row10_col8\" class=\"data row10 col8\" >585.47 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_93a06_row11_col0\" class=\"data row11 col0\" >tallwaterfall.mp4</td>\n",
       "      <td id=\"T_93a06_row11_col1\" class=\"data row11 col1\" >2.85 MB</td>\n",
       "      <td id=\"T_93a06_row11_col2\" class=\"data row11 col2\" >299</td>\n",
       "      <td id=\"T_93a06_row11_col3\" class=\"data row11 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row11_col4\" class=\"data row11 col4\" >12</td>\n",
       "      <td id=\"T_93a06_row11_col5\" class=\"data row11 col5\" >31.47 MB</td>\n",
       "      <td id=\"T_93a06_row11_col6\" class=\"data row11 col6\" >0.07 MB</td>\n",
       "      <td id=\"T_93a06_row11_col7\" class=\"data row11 col7\" >97.52 %</td>\n",
       "      <td id=\"T_93a06_row11_col8\" class=\"data row11 col8\" >1101.42 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_93a06_row12_col0\" class=\"data row12 col0\" >wavescrash.mp4</td>\n",
       "      <td id=\"T_93a06_row12_col1\" class=\"data row12 col1\" >5.98 MB</td>\n",
       "      <td id=\"T_93a06_row12_col2\" class=\"data row12 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row12_col3\" class=\"data row12 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row12_col4\" class=\"data row12 col4\" >14</td>\n",
       "      <td id=\"T_93a06_row12_col5\" class=\"data row12 col5\" >29.85 MB</td>\n",
       "      <td id=\"T_93a06_row12_col6\" class=\"data row12 col6\" >0.06 MB</td>\n",
       "      <td id=\"T_93a06_row12_col7\" class=\"data row12 col7\" >98.98 %</td>\n",
       "      <td id=\"T_93a06_row12_col8\" class=\"data row12 col8\" >498.42 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_93a06_row13_col0\" class=\"data row13 col0\" >countrysideaerial.mp4</td>\n",
       "      <td id=\"T_93a06_row13_col1\" class=\"data row13 col1\" >0.61 MB</td>\n",
       "      <td id=\"T_93a06_row13_col2\" class=\"data row13 col2\" >299</td>\n",
       "      <td id=\"T_93a06_row13_col3\" class=\"data row13 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row13_col4\" class=\"data row13 col4\" >12</td>\n",
       "      <td id=\"T_93a06_row13_col5\" class=\"data row13 col5\" >14.27 MB</td>\n",
       "      <td id=\"T_93a06_row13_col6\" class=\"data row13 col6\" >0.02 MB</td>\n",
       "      <td id=\"T_93a06_row13_col7\" class=\"data row13 col7\" >96.00 %</td>\n",
       "      <td id=\"T_93a06_row13_col8\" class=\"data row13 col8\" >2320.78 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_93a06_row14_col0\" class=\"data row14 col0\" >waterrocks.mp4</td>\n",
       "      <td id=\"T_93a06_row14_col1\" class=\"data row14 col1\" >7.43 MB</td>\n",
       "      <td id=\"T_93a06_row14_col2\" class=\"data row14 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row14_col3\" class=\"data row14 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row14_col4\" class=\"data row14 col4\" >13</td>\n",
       "      <td id=\"T_93a06_row14_col5\" class=\"data row14 col5\" >21.79 MB</td>\n",
       "      <td id=\"T_93a06_row14_col6\" class=\"data row14 col6\" >0.05 MB</td>\n",
       "      <td id=\"T_93a06_row14_col7\" class=\"data row14 col7\" >99.31 %</td>\n",
       "      <td id=\"T_93a06_row14_col8\" class=\"data row14 col8\" >292.58 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_93a06_row15_col0\" class=\"data row15 col0\" >oilrig.mp4</td>\n",
       "      <td id=\"T_93a06_row15_col1\" class=\"data row15 col1\" >2.88 MB</td>\n",
       "      <td id=\"T_93a06_row15_col2\" class=\"data row15 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row15_col3\" class=\"data row15 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row15_col4\" class=\"data row15 col4\" >13</td>\n",
       "      <td id=\"T_93a06_row15_col5\" class=\"data row15 col5\" >5.42 MB</td>\n",
       "      <td id=\"T_93a06_row15_col6\" class=\"data row15 col6\" >0.02 MB</td>\n",
       "      <td id=\"T_93a06_row15_col7\" class=\"data row15 col7\" >99.44 %</td>\n",
       "      <td id=\"T_93a06_row15_col8\" class=\"data row15 col8\" >187.70 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_93a06_row16_col0\" class=\"data row16 col0\" >hiills.mp4</td>\n",
       "      <td id=\"T_93a06_row16_col1\" class=\"data row16 col1\" >1.23 MB</td>\n",
       "      <td id=\"T_93a06_row16_col2\" class=\"data row16 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row16_col3\" class=\"data row16 col3\" >30.00 FPS</td>\n",
       "      <td id=\"T_93a06_row16_col4\" class=\"data row16 col4\" >13</td>\n",
       "      <td id=\"T_93a06_row16_col5\" class=\"data row16 col5\" >20.63 MB</td>\n",
       "      <td id=\"T_93a06_row16_col6\" class=\"data row16 col6\" >0.03 MB</td>\n",
       "      <td id=\"T_93a06_row16_col7\" class=\"data row16 col7\" >97.54 %</td>\n",
       "      <td id=\"T_93a06_row16_col8\" class=\"data row16 col8\" >1678.81 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_93a06_row17_col0\" class=\"data row17 col0\" >yellowinkflowing.mp4</td>\n",
       "      <td id=\"T_93a06_row17_col1\" class=\"data row17 col1\" >1.34 MB</td>\n",
       "      <td id=\"T_93a06_row17_col2\" class=\"data row17 col2\" >250</td>\n",
       "      <td id=\"T_93a06_row17_col3\" class=\"data row17 col3\" >25.00 FPS</td>\n",
       "      <td id=\"T_93a06_row17_col4\" class=\"data row17 col4\" >10</td>\n",
       "      <td id=\"T_93a06_row17_col5\" class=\"data row17 col5\" >11.70 MB</td>\n",
       "      <td id=\"T_93a06_row17_col6\" class=\"data row17 col6\" >0.04 MB</td>\n",
       "      <td id=\"T_93a06_row17_col7\" class=\"data row17 col7\" >96.72 %</td>\n",
       "      <td id=\"T_93a06_row17_col8\" class=\"data row17 col8\" >872.36 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_93a06_row18_col0\" class=\"data row18 col0\" >clouds.mp4</td>\n",
       "      <td id=\"T_93a06_row18_col1\" class=\"data row18 col1\" >1.43 MB</td>\n",
       "      <td id=\"T_93a06_row18_col2\" class=\"data row18 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row18_col3\" class=\"data row18 col3\" >30.00 FPS</td>\n",
       "      <td id=\"T_93a06_row18_col4\" class=\"data row18 col4\" >12</td>\n",
       "      <td id=\"T_93a06_row18_col5\" class=\"data row18 col5\" >7.93 MB</td>\n",
       "      <td id=\"T_93a06_row18_col6\" class=\"data row18 col6\" >0.02 MB</td>\n",
       "      <td id=\"T_93a06_row18_col7\" class=\"data row18 col7\" >98.62 %</td>\n",
       "      <td id=\"T_93a06_row18_col8\" class=\"data row18 col8\" >551.85 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_93a06_row19_col0\" class=\"data row19 col0\" >stormcloundsaerial.mp4</td>\n",
       "      <td id=\"T_93a06_row19_col1\" class=\"data row19 col1\" >0.91 MB</td>\n",
       "      <td id=\"T_93a06_row19_col2\" class=\"data row19 col2\" >250</td>\n",
       "      <td id=\"T_93a06_row19_col3\" class=\"data row19 col3\" >25.00 FPS</td>\n",
       "      <td id=\"T_93a06_row19_col4\" class=\"data row19 col4\" >11</td>\n",
       "      <td id=\"T_93a06_row19_col5\" class=\"data row19 col5\" >10.14 MB</td>\n",
       "      <td id=\"T_93a06_row19_col6\" class=\"data row19 col6\" >0.03 MB</td>\n",
       "      <td id=\"T_93a06_row19_col7\" class=\"data row19 col7\" >96.61 %</td>\n",
       "      <td id=\"T_93a06_row19_col8\" class=\"data row19 col8\" >1113.46 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_93a06_row20_col0\" class=\"data row20 col0\" >riverthroughboulders.mp4</td>\n",
       "      <td id=\"T_93a06_row20_col1\" class=\"data row20 col1\" >10.41 MB</td>\n",
       "      <td id=\"T_93a06_row20_col2\" class=\"data row20 col2\" >299</td>\n",
       "      <td id=\"T_93a06_row20_col3\" class=\"data row20 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row20_col4\" class=\"data row20 col4\" >12</td>\n",
       "      <td id=\"T_93a06_row20_col5\" class=\"data row20 col5\" >39.42 MB</td>\n",
       "      <td id=\"T_93a06_row20_col6\" class=\"data row20 col6\" >0.10 MB</td>\n",
       "      <td id=\"T_93a06_row20_col7\" class=\"data row20 col7\" >99.07 %</td>\n",
       "      <td id=\"T_93a06_row20_col8\" class=\"data row20 col8\" >377.75 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_93a06_row21_col0\" class=\"data row21 col0\" >waterfallthroughrockymountain.mp4</td>\n",
       "      <td id=\"T_93a06_row21_col1\" class=\"data row21 col1\" >2.12 MB</td>\n",
       "      <td id=\"T_93a06_row21_col2\" class=\"data row21 col2\" >299</td>\n",
       "      <td id=\"T_93a06_row21_col3\" class=\"data row21 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row21_col4\" class=\"data row21 col4\" >13</td>\n",
       "      <td id=\"T_93a06_row21_col5\" class=\"data row21 col5\" >23.58 MB</td>\n",
       "      <td id=\"T_93a06_row21_col6\" class=\"data row21 col6\" >0.04 MB</td>\n",
       "      <td id=\"T_93a06_row21_col7\" class=\"data row21 col7\" >98.01 %</td>\n",
       "      <td id=\"T_93a06_row21_col8\" class=\"data row21 col8\" >1111.29 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_93a06_row22_col0\" class=\"data row22 col0\" >lighthouse.mp4</td>\n",
       "      <td id=\"T_93a06_row22_col1\" class=\"data row22 col1\" >1.40 MB</td>\n",
       "      <td id=\"T_93a06_row22_col2\" class=\"data row22 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row22_col3\" class=\"data row22 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row22_col4\" class=\"data row22 col4\" >12</td>\n",
       "      <td id=\"T_93a06_row22_col5\" class=\"data row22 col5\" >14.60 MB</td>\n",
       "      <td id=\"T_93a06_row22_col6\" class=\"data row22 col6\" >0.03 MB</td>\n",
       "      <td id=\"T_93a06_row22_col7\" class=\"data row22 col7\" >97.61 %</td>\n",
       "      <td id=\"T_93a06_row22_col8\" class=\"data row22 col8\" >1036.87 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_93a06_row23_col0\" class=\"data row23 col0\" >nightsky.mp4</td>\n",
       "      <td id=\"T_93a06_row23_col1\" class=\"data row23 col1\" >1.68 MB</td>\n",
       "      <td id=\"T_93a06_row23_col2\" class=\"data row23 col2\" >240</td>\n",
       "      <td id=\"T_93a06_row23_col3\" class=\"data row23 col3\" >23.98 FPS</td>\n",
       "      <td id=\"T_93a06_row23_col4\" class=\"data row23 col4\" >11</td>\n",
       "      <td id=\"T_93a06_row23_col5\" class=\"data row23 col5\" >25.66 MB</td>\n",
       "      <td id=\"T_93a06_row23_col6\" class=\"data row23 col6\" >0.04 MB</td>\n",
       "      <td id=\"T_93a06_row23_col7\" class=\"data row23 col7\" >97.80 %</td>\n",
       "      <td id=\"T_93a06_row23_col8\" class=\"data row23 col8\" >1524.12 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_93a06_row24_col0\" class=\"data row24 col0\" >creek.mp4</td>\n",
       "      <td id=\"T_93a06_row24_col1\" class=\"data row24 col1\" >3.23 MB</td>\n",
       "      <td id=\"T_93a06_row24_col2\" class=\"data row24 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row24_col3\" class=\"data row24 col3\" >29.97 FPS</td>\n",
       "      <td id=\"T_93a06_row24_col4\" class=\"data row24 col4\" >11</td>\n",
       "      <td id=\"T_93a06_row24_col5\" class=\"data row24 col5\" >30.50 MB</td>\n",
       "      <td id=\"T_93a06_row24_col6\" class=\"data row24 col6\" >0.06 MB</td>\n",
       "      <td id=\"T_93a06_row24_col7\" class=\"data row24 col7\" >98.06 %</td>\n",
       "      <td id=\"T_93a06_row24_col8\" class=\"data row24 col8\" >943.55 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_93a06_row25_col0\" class=\"data row25 col0\" >snowtrees.mp4</td>\n",
       "      <td id=\"T_93a06_row25_col1\" class=\"data row25 col1\" >6.40 MB</td>\n",
       "      <td id=\"T_93a06_row25_col2\" class=\"data row25 col2\" >240</td>\n",
       "      <td id=\"T_93a06_row25_col3\" class=\"data row25 col3\" >23.98 FPS</td>\n",
       "      <td id=\"T_93a06_row25_col4\" class=\"data row25 col4\" >11</td>\n",
       "      <td id=\"T_93a06_row25_col5\" class=\"data row25 col5\" >42.82 MB</td>\n",
       "      <td id=\"T_93a06_row25_col6\" class=\"data row25 col6\" >0.12 MB</td>\n",
       "      <td id=\"T_93a06_row25_col7\" class=\"data row25 col7\" >98.07 %</td>\n",
       "      <td id=\"T_93a06_row25_col8\" class=\"data row25 col8\" >667.51 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_93a06_row26_col0\" class=\"data row26 col0\" >citycoast.mp4</td>\n",
       "      <td id=\"T_93a06_row26_col1\" class=\"data row26 col1\" >4.03 MB</td>\n",
       "      <td id=\"T_93a06_row26_col2\" class=\"data row26 col2\" >300</td>\n",
       "      <td id=\"T_93a06_row26_col3\" class=\"data row26 col3\" >30.00 FPS</td>\n",
       "      <td id=\"T_93a06_row26_col4\" class=\"data row26 col4\" >13</td>\n",
       "      <td id=\"T_93a06_row26_col5\" class=\"data row26 col5\" >29.72 MB</td>\n",
       "      <td id=\"T_93a06_row26_col6\" class=\"data row26 col6\" >0.05 MB</td>\n",
       "      <td id=\"T_93a06_row26_col7\" class=\"data row26 col7\" >98.65 %</td>\n",
       "      <td id=\"T_93a06_row26_col8\" class=\"data row26 col8\" >736.71 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a06_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_93a06_row27_col0\" class=\"data row27 col0\" >cliffwater.mp4</td>\n",
       "      <td id=\"T_93a06_row27_col1\" class=\"data row27 col1\" >1.87 MB</td>\n",
       "      <td id=\"T_93a06_row27_col2\" class=\"data row27 col2\" >600</td>\n",
       "      <td id=\"T_93a06_row27_col3\" class=\"data row27 col3\" >59.94 FPS</td>\n",
       "      <td id=\"T_93a06_row27_col4\" class=\"data row27 col4\" >21</td>\n",
       "      <td id=\"T_93a06_row27_col5\" class=\"data row27 col5\" >26.83 MB</td>\n",
       "      <td id=\"T_93a06_row27_col6\" class=\"data row27 col6\" >0.03 MB</td>\n",
       "      <td id=\"T_93a06_row27_col7\" class=\"data row27 col7\" >98.48 %</td>\n",
       "      <td id=\"T_93a06_row27_col8\" class=\"data row27 col8\" >1431.86 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7b883b5b5400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT PUT _ in the input directory name. We parse at the _ to get the timestamp of the frame. This can mess up the paths. \n",
    "input_dir = \"/root/VideoReconstruction/alloriginalvids\" # this is the directory where the input videos are stored. \n",
    "output_dir_base = \"/root/VideoReconstruction/outputs/bucketedkeyframes\"\n",
    "smaller_video_output_dir = \"/root/VideoReconstruction/outputs/bucketed_keyframes_video\"\n",
    "\n",
    "# !rm -rf $output_dir_base\n",
    "# !rm -rf $smaller_video_output_dir\n",
    "\n",
    "os.makedirs(output_dir_base, exist_ok=True)\n",
    "os.makedirs(smaller_video_output_dir, exist_ok=True)\n",
    "\n",
    "videos = os.listdir(input_dir)\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "evaluator = FFmpegEvaluator()\n",
    "\n",
    "interims = \"./interims\"\n",
    "os.makedirs(\"./interims\", exist_ok=True)\n",
    "\n",
    "for video in videos:\n",
    "    video_path = os.path.join(input_dir, video)\n",
    "    video_name = os.path.splitext(video)[0]\n",
    "    output_dir = os.path.join(output_dir_base, video_name)\n",
    "    interim_output_path = os.path.join(interims, f\"{video_name}_resized.mp4\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = total_frames / fps\n",
    "    cap.release()\n",
    "    command = [\n",
    "        'ffmpeg',\n",
    "        '-i', video_path,  # Input video\n",
    "        '-r', str(fps),  # Set frame rate\n",
    "        '-vf', 'scale=1024:576',  # Resize to 1024x576\n",
    "        '-c:v', 'libx264',  # Use H.264 codec\n",
    "        '-pix_fmt', 'yuv420p',  # Set pixel format\n",
    "        '-t', str(duration),  \n",
    "        '-y',  # Overwrite existing file\n",
    "        interim_output_path\n",
    "    ]\n",
    "    \n",
    "    process = subprocess.run(command, check=True, capture_output=True)\n",
    "\n",
    "    video_size_in_bytes = os.path.getsize(interim_output_path)\n",
    "    video_size_in_megabytes = video_size_in_bytes / (1024 * 1024)\n",
    "    if video_name not in os.listdir(output_dir_base):\n",
    "        smartKeyframeDetection(\n",
    "            video_path,\n",
    "            bucket_size_in_frames,\n",
    "            threshold,\n",
    "            output_dir,\n",
    "            minimum_frames_in_between,\n",
    "            maximum_frames_in_between,\n",
    "            segment_fps,\n",
    "            top_k_no_interpolation\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Skipping {video_name} as it is already processed\")\n",
    "        continue\n",
    "        \n",
    "    # get directory size\n",
    "    keyframes = os.listdir(output_dir)\n",
    "    keyframe_count = len(keyframes)\n",
    "\n",
    "    keyframes_dir_size_in_bytes = get_directory_size(output_dir)\n",
    "    keyframes_dir_size_in_megabytes = keyframes_dir_size_in_bytes / (1024 * 1024)\n",
    "\n",
    "    compressed_size, savings_from_original_video, savings_from_keyframes_video = evaluator.evaluate_smaller_video(\n",
    "        interim_output_path, smaller_video_output_dir, output_dir)\n",
    "\n",
    "    summary_data.append(\n",
    "        [\n",
    "            video,\n",
    "            f\"{video_size_in_megabytes:.2f} MB\",\n",
    "            total_frames,\n",
    "            f\"{fps:.2f} FPS\",\n",
    "            keyframe_count,\n",
    "            f\"{keyframes_dir_size_in_megabytes:.2f} MB\",\n",
    "            f\"{compressed_size/(1024*1024):.2f} MB\",\n",
    "            f\"{savings_from_original_video:.2f} %\",\n",
    "            f\"{savings_from_keyframes_video:.2f} %\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "headers = [\n",
    "    \"Video Name\",\n",
    "    \"Original Size\",\n",
    "    \"Total Frames\",\n",
    "    \"FPS\",\n",
    "    \"Total Keyframes\",\n",
    "    \"Keyframes Size\",\n",
    "    \"Compressed Video Size\",\n",
    "    \"Savings Original Video\",\n",
    "    \"Savings Keyframes Video\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(summary_data, columns=headers)\n",
    "output_csv_path = \"/root/VideoReconstruction/logs/bandwidth_savings_data.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "shutil.rmtree(interims)\n",
    "\n",
    "df.style.set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('font-weight', 'bold'), ('background-color', '#000000')]}]\n",
    ").set_properties(**{'text-align': 'center'})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Settings for Image-to-Video Interpolation:\n",
      "+------------------------------+-----------------------------------------------+\n",
      "| Parameter                    | Value                                         |\n",
      "+==============================+===============================================+\n",
      "| Model                        | stabilityai/stable-video-diffusion-img2vid-xt |\n",
      "+------------------------------+-----------------------------------------------+\n",
      "| Output Directory             | /root/VideoReconstruction/our_results         |\n",
      "+------------------------------+-----------------------------------------------+\n",
      "| Resize Specifications        | 1024 x 576                                    |\n",
      "+------------------------------+-----------------------------------------------+\n",
      "| FPS                          | 25                                            |\n",
      "+------------------------------+-----------------------------------------------+\n",
      "| Frame Duration (ms)          | 142                                           |\n",
      "+------------------------------+-----------------------------------------------+\n",
      "| Inference Steps              | 15                                            |\n",
      "+------------------------------+-----------------------------------------------+\n",
      "| Random Seed                  | 42                                            |\n",
      "+------------------------------+-----------------------------------------------+\n",
      "| Saving interpolated video as | mp4 video file                                |\n",
      "+------------------------------+-----------------------------------------------+\n",
      "| Number of Frames             | 24                                            |\n",
      "+------------------------------+-----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# INPUT_DIR is the directory from which the keyframes will be read\n",
    "# DO NOT PUT _ in the input directory name. We parse at the _ to get the timestamp of the frame. This can mess up the paths. \n",
    "\n",
    "INPUT_DIR = \"/root/VideoReconstruction/outputs/bucketedkeyframes\"\n",
    "OUT_DIR = \"/root/VideoReconstruction/our_results\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "CHECKPOINT_DIR = \"/root/VideoReconstruction/svd/checkpoints/svd_reverse_motion_with_attnflip/svd_reverse_motion_with_attnflip/unet\"  # path for docker image\n",
    "\n",
    "threshold = 0.3\n",
    "\n",
    "# Model options and selection. maybe we cam add more models later for this\n",
    "models_to_try = [\"stabilityai/stable-video-diffusion-img2vid-xt\",\n",
    "                 \"stabilityai/stable-video-diffusion-img2vid-xt-1-1\"]\n",
    "MODEL_NAME = models_to_try[0]\n",
    "\n",
    "# Noise injection parameters\n",
    "noise_injection_steps = 2\n",
    "noise_injection_ratio = 0.5\n",
    "\n",
    "# if this is .gif, the output will be a gif otherwise it will be a video\n",
    "interpolation_extension = \".mp4\"\n",
    "final_extension = \".mp4\"\n",
    "\n",
    "# Resize specifications, frame rate, and duration etc\n",
    "resize_specs = (1024, 576)\n",
    "fps = 25 # the frame rate of the output video\n",
    "duration = 142  # the duration for which each frame is displayed in the vid\n",
    "inference_steps = 15 # The number of denoising steps. More denoising steps usually lead to a higher quality image at the expense of slower inference.\n",
    "seed = 42\n",
    "decode_chunk_size = 6 # controls how many frames are decoded at a time from the latent representations during the video generation process. A smaller value will use less memory but may be slower. The higher the chunk size, the higher the temporal consistency between frames, but also the higher the memory consumption. By default, the decoder will decode all frames at once for maximal quality. Reduce `decode_chunk_size` to reduce memory usage.\n",
    "num_frames = 24 #  The number of frames to decode at a time. We decide these dynamically based on the timestamps of the frames.\n",
    "\n",
    "# ===========================\n",
    "# Display Configuration\n",
    "# ===========================\n",
    "\n",
    "settings = [\n",
    "    [\"Model\", MODEL_NAME],\n",
    "    [\"Output Directory\", OUT_DIR],\n",
    "    [\"Resize Specifications\", f\"{resize_specs[0]} x {resize_specs[1]}\"],\n",
    "    [\"FPS\", fps],\n",
    "    [\"Frame Duration (ms)\", duration],\n",
    "    [\"Inference Steps\", inference_steps],\n",
    "    [\"Random Seed\", seed],\n",
    "    [\"Saving interpolated video as\", \"gif file\" if interpolation_extension ==\n",
    "        \".gif\" else \"mp4 video file\"],\n",
    "    [\"Number of Frames\", num_frames],\n",
    "]\n",
    "\n",
    "print(\"\\nSettings for Image-to-Video Interpolation:\")\n",
    "print(tabulate(settings, headers=[\"Parameter\", \"Value\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looped interpolation\n",
    "\n",
    "Here, we loop through all the videos in the input folder, generate keyframes for them and then interpolate between the keyframes to get the final video. This is done for all the videos in the input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each file in the input directory\n",
    "\n",
    "for filename in os.listdir(INPUT_DIR):\n",
    "    \n",
    "    vids_done = os.listdir(\"./our_results/\")\n",
    "    start_time = time.time()\n",
    "    video_name = os.path.splitext(filename)[0] \n",
    "    video_path = os.path.join(INPUT_DIR, filename)\n",
    "    \n",
    "    if f\"{video_name}_interpolated{final_extension}\" in vids_done:\n",
    "        print(f\"Skipping {video_name} as it is already done\")\n",
    "        continue\n",
    "    try:\n",
    "        generate_all_interpolations(\n",
    "            checkpoint_dir=CHECKPOINT_DIR, \n",
    "            input_sub_dir=os.path.join(INPUT_DIR, video_name), \n",
    "            output_dir=OUT_DIR, \n",
    "            model_name=MODEL_NAME, \n",
    "            resize_specs=resize_specs, \n",
    "            fps=fps, \n",
    "            duration=duration, \n",
    "            extension=interpolation_extension,\n",
    "            seed=seed, \n",
    "            inference_steps=inference_steps, \n",
    "            noise_injection_steps=noise_injection_steps, \n",
    "            noise_injection_ratio=noise_injection_ratio, \n",
    "            decode_chunk_size=decode_chunk_size, \n",
    "            num_frames=num_frames, \n",
    "            video_name=video_name\n",
    "        )\n",
    "        stitch_video_segments(\n",
    "            intermediate_videos_dir=os.path.join(OUT_DIR, f\"interm_videos_{video_name}\"), \n",
    "            output_path=os.path.join(OUT_DIR, f\"{video_name}_interpolated{final_extension}\"), \n",
    "            fps=fps\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error while generate_all_interpolations\")\n",
    "        print(f\"Error: {e}\")\n",
    "        # Kill the kernel processes on GPU errors\n",
    "        print(\"Killing the kernel processes\")\n",
    "        env_name = os.path.basename(sys.prefix)\n",
    "        subprocess.call(\n",
    "            f\"nvidia-smi | grep {env_name} | awk '{{print $5}}' | xargs -I {{}} kill -9 {{}}\",\n",
    "            shell=True\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        raise e\n",
    "\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        pass\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time for {video_name}: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inidvidual Video Processing\n",
    "\n",
    "You can uncomment the below cell to run the interpolation for a single video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/root/VideoReconstruction/input_videos/cliffwater.mp4\"\n",
    "output_keyframes_dir_base = \"/root/VideoReconstruction/outputs/bucketedkeyframes\"\n",
    "output_video_dir = \"/root/VideoReconstruction/our_results/\"\n",
    "video_name = os.path.splitext(os.path.basename(input_dir))[0]\n",
    "os.makedirs(output_keyframes_dir_base, exist_ok=True)\n",
    "output_keyframes_dir = os.path.join(output_keyframes_dir_base, video_name)\n",
    "\n",
    "# if the keyframes have not been generated then uncomment the below line as well. otherwise comment it out to prevent time wastage. It will not cause an error if you generate the keyframes again but it will be a waste of time\n",
    "\n",
    "smartKeyframeDetection(input_dir, bucket_size_in_frames, threshold, output_keyframes_dir_base, minimum_frames_in_between, maximum_frames_in_between, segment_fps, top_k_no_interpolation)\n",
    "\n",
    "try:\n",
    "    generate_all_interpolations(checkpoint_dir=CHECKPOINT_DIR, input_sub_dir=output_keyframes_dir, output_dir=output_video_dir, model_name=MODEL_NAME, resize_specs=resize_specs, fps=fps, duration=duration, extension=interpolation_extension,\n",
    "                    seed=seed, inference_steps=inference_steps, noise_injection_steps=noise_injection_steps, noise_injection_ratio=noise_injection_ratio, decode_chunk_size=decode_chunk_size, num_frames=num_frames)\n",
    "    stitch_video_segments(intermediate_videos_dir=os.path.join(OUT_DIR, f\"interm_videos_{video_name}\"), output_path=os.path.join(\n",
    "            OUT_DIR, f\"{video_name}_interpolated{final_extension}\"), fps=fps)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Killing the kernel processes\")\n",
    "    env_name = os.path.basename(sys.prefix)\n",
    "    subprocess.call(\n",
    "    f\"nvidia-smi | grep {env_name} | awk '{{print $5}}' | xargs -I {{}} kill -9 {{}}\",\n",
    "    shell=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can kill the kernel processes after we are done with the interpolation to clear up GPU memory\n",
    "\n",
    "!nvidia-smi | grep $(conda env list | grep '*' | awk '{print $1}') | awk '{print $5}' | xargs -I {} kill -9 {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 17 13:24:07 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:01:00.0  On |                  Off |\n",
      "|  0%   41C    P5              22W / 450W |  23257MiB / 24564MiB |     28%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
